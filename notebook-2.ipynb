{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe23d5d-a35f-47e8-8003-a6bd8269b195",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "\n",
    "1. Updated implementation of the perturbation process using the Uniform distribution and setting the perturbation factor.\n",
    "\n",
    "2. Correct rule criterion (use the $\\math{{y}^{^}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213599e-4f3c-4c1b-b47b-ec3959a2445a",
   "metadata": {},
   "source": [
    "$$ y^{~^} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55520e61-3dd6-4e45-bc3b-727066c946ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2426c5-fb05-45f1-b810-fadd2eb096e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/cardio_train.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b28d236-f288-41c8-a5f3-f1339d26379e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8c88e4-74fc-4421-bb53-a8a02e3f125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf98f68-3fbc-4573-aa9b-66b3a30c98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `id` feature\n",
    "data.drop(labels = [\"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5e5554-819f-4d1c-a24c-690be106b087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            8076\n",
       "gender            2\n",
       "height          109\n",
       "weight          287\n",
       "ap_hi           153\n",
       "ap_lo           157\n",
       "cholesterol       3\n",
       "gluc              3\n",
       "smoke             2\n",
       "alco              2\n",
       "active            2\n",
       "cardio            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cardinality\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658a229e-b717-49d3-87be-a4793edb696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"gender\",\n",
    "    \"cholesterol\",\n",
    "    \"gluc\",\n",
    "    \"smoke\",\n",
    "    \"alco\",\n",
    "    \"active\",\n",
    "]\n",
    "\n",
    "scale_features = [\n",
    "    \"age\",\n",
    "    \"height\",\n",
    "    \"weight\",\n",
    "    \"ap_hi\",\n",
    "    \"ap_lo\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b797f346-a5f3-40a6-be06-20892591960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b307357e-7a1d-4013-9dc5-9b4ddcc02cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65deb4dc-33a0-4c38-b642-ee9488b1cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and target\n",
    "X, y = data.drop(labels = [\"cardio\"], axis = 1), data[\"cardio\"]\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size = .4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9041cbc-7480-4d25-96f4-cbbdd7d890cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>22586</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>68.0</td>\n",
       "      <td>160</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16111</th>\n",
       "      <td>16110</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>78.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31190</th>\n",
       "      <td>21934</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>78.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24372</th>\n",
       "      <td>22669</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>88.0</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68629</th>\n",
       "      <td>23389</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>74.0</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "6184   22586       1     165    68.0    160     80            1     1      0   \n",
       "16111  16110       2     175    78.0    120     80            1     1      1   \n",
       "31190  21934       1     158    78.0    130     80            1     1      0   \n",
       "24372  22669       2     174    88.0    160     90            3     3      0   \n",
       "68629  23389       1     156    74.0    140    100            1     1      0   \n",
       "\n",
       "       alco  active  \n",
       "6184      0       1  \n",
       "16111     0       1  \n",
       "31190     0       1  \n",
       "24372     0       1  \n",
       "68629     0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6365669d-f90f-4348-bbfe-8c4690862680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit encoder\n",
    "encoder.fit(X_train.loc[:, categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0853ad88-b5f4-4d0c-8b27-298d1447913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_1', 'gender_2', 'cholesterol_1', 'cholesterol_2',\n",
       "       'cholesterol_3', 'gluc_1', 'gluc_2', 'gluc_3', 'smoke_0',\n",
       "       'smoke_1', 'alco_0', 'alco_1', 'active_0', 'active_1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae6ee52-57de-4bb9-9f9f-a57711a4aa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(X_train.loc[:, categorical_features]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8df29d6-cdd4-4502-86e6-15eb7f4763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train, test, categorical_features):\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "\n",
    "    encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"encoder\", OneHotEncoder(), categorical_features),\n",
    "            (\"scaler\", StandardScaler(), scale_features)\n",
    "        ],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "    encoder.fit(X_train)\n",
    "    columns = encoder.get_feature_names_out()\n",
    "\n",
    "    X_train = encoder.transform(X_train)\n",
    "    X_test = encoder.transform(X_test)\n",
    "\n",
    "    X_train = pd.DataFrame(data = X_train, columns = columns)\n",
    "    X_test = pd.DataFrame(data = X_test, columns = columns)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a128d07-bda3-4558-92dc-359917974946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = transform_data([X_train, y_train], [X_test, y_test], categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4a1b51-e1f5-424c-a304-d3382ba94c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__gender_1</th>\n",
       "      <th>encoder__gender_2</th>\n",
       "      <th>encoder__cholesterol_1</th>\n",
       "      <th>encoder__cholesterol_2</th>\n",
       "      <th>encoder__cholesterol_3</th>\n",
       "      <th>encoder__gluc_1</th>\n",
       "      <th>encoder__gluc_2</th>\n",
       "      <th>encoder__gluc_3</th>\n",
       "      <th>encoder__smoke_0</th>\n",
       "      <th>encoder__smoke_1</th>\n",
       "      <th>encoder__alco_0</th>\n",
       "      <th>encoder__alco_1</th>\n",
       "      <th>encoder__active_0</th>\n",
       "      <th>encoder__active_1</th>\n",
       "      <th>scaler__age</th>\n",
       "      <th>scaler__height</th>\n",
       "      <th>scaler__weight</th>\n",
       "      <th>scaler__ap_hi</th>\n",
       "      <th>scaler__ap_lo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.263613</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>-0.427516</td>\n",
       "      <td>0.205307</td>\n",
       "      <td>-0.092932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358803</td>\n",
       "      <td>1.285136</td>\n",
       "      <td>0.265649</td>\n",
       "      <td>-0.057572</td>\n",
       "      <td>-0.092932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>-0.771676</td>\n",
       "      <td>0.265649</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>-0.092932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.297223</td>\n",
       "      <td>1.164147</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.205307</td>\n",
       "      <td>-0.036404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.588783</td>\n",
       "      <td>-1.013654</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.073867</td>\n",
       "      <td>0.020124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoder__gender_1  encoder__gender_2  encoder__cholesterol_1  \\\n",
       "0                1.0                0.0                     1.0   \n",
       "1                0.0                1.0                     1.0   \n",
       "2                1.0                0.0                     1.0   \n",
       "3                0.0                1.0                     0.0   \n",
       "4                1.0                0.0                     1.0   \n",
       "\n",
       "   encoder__cholesterol_2  encoder__cholesterol_3  encoder__gluc_1  \\\n",
       "0                     0.0                     0.0              1.0   \n",
       "1                     0.0                     0.0              1.0   \n",
       "2                     0.0                     0.0              1.0   \n",
       "3                     0.0                     1.0              0.0   \n",
       "4                     0.0                     0.0              1.0   \n",
       "\n",
       "   encoder__gluc_2  encoder__gluc_3  encoder__smoke_0  encoder__smoke_1  \\\n",
       "0              0.0              0.0               1.0               0.0   \n",
       "1              0.0              0.0               0.0               1.0   \n",
       "2              0.0              0.0               1.0               0.0   \n",
       "3              0.0              1.0               1.0               0.0   \n",
       "4              0.0              0.0               1.0               0.0   \n",
       "\n",
       "   encoder__alco_0  encoder__alco_1  encoder__active_0  encoder__active_1  \\\n",
       "0              1.0              0.0                0.0                1.0   \n",
       "1              1.0              0.0                0.0                1.0   \n",
       "2              1.0              0.0                0.0                1.0   \n",
       "3              1.0              0.0                0.0                1.0   \n",
       "4              1.0              0.0                1.0                0.0   \n",
       "\n",
       "   scaler__age  scaler__height  scaler__weight  scaler__ap_hi  scaler__ap_lo  \n",
       "0     1.263613        0.075246       -0.427516       0.205307      -0.092932  \n",
       "1    -1.358803        1.285136        0.265649      -0.057572      -0.092932  \n",
       "2     0.999590       -0.771676        0.265649       0.008148      -0.092932  \n",
       "3     1.297223        1.164147        0.958815       0.205307      -0.036404  \n",
       "4     1.588783       -1.013654       -0.011617       0.073867       0.020124  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f623e5-3f5b-4ca4-a9db-6fbc971d0086",
   "metadata": {},
   "source": [
    "### Model Design\n",
    "\n",
    "Architectures of interest:\n",
    "+ Encoders: [FC100,ReLU,FC16]\n",
    "+ Decision block: [FC1,Sigmoid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf4a1c9-b138-4d99-a7ac-55175a74f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c15a5434-32a7-4cb0-bbb4-bbb2b587836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, out_features)\n",
    "\n",
    "    def forward(self, x,):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217093ed-4ae3-42d0-8ae1-8e06a502f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be7100f0-81b3-498b-8f29-b99aaf3ce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    \"\"\"Combines rule and data encoders and decision block.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, combination_method=\"concat\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.method = combination_method # How to combine rule and data results\n",
    "        \n",
    "        self.data_encoder = Encoder(in_features = in_features, out_features = out_features)\n",
    "        self.rule_encoder = Encoder(in_features = in_features, out_features = out_features)\n",
    "\n",
    "        if self.method == \"concat\":\n",
    "            decision_input_size = out_features * 2\n",
    "        elif self.method == \"add\":\n",
    "            decision_input_size = out_features\n",
    "        \n",
    "        self.decision_block = DecisionBlock(in_features = decision_input_size)\n",
    "\n",
    "    def combine_encodings(self, rule_encoding, data_encoding, alpha_factor):\n",
    "        if self.method == \"add\":\n",
    "            x = self.add_encodings(rule_encoding=rule_encoding, data_encoding=data_encoding, alpha_factor=alpha_factor)\n",
    "        elif self.method == \"concat\":\n",
    "            x = self.concatenate_encodings(rule_encoding=rule_encoding, data_encoding=data_encoding, alpha_factor=alpha_factor)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def add_encodings(self, rule_encoding, data_encoding, alpha_factor):\n",
    "        x = (alpha_factor * rule_encoding) + ((1 - alpha_factor) * data_encoding)\n",
    "        return x\n",
    "\n",
    "    def concatenate_encodings(self, rule_encoding, data_encoding, alpha_factor):\n",
    "        x = torch.cat([(alpha_factor * rule_encoding), ((1 - alpha_factor) * data_encoding)], dim = -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, alpha_factor=0.):\n",
    "        rule_encoding = self.rule_encoder(x) # Get rule encoding\n",
    "        data_encoding = self.data_encoder(x) # Get data encoding\n",
    "\n",
    "        combined_encodings = self.combine_encodings(\n",
    "            rule_encoding=rule_encoding,\n",
    "            data_encoding=data_encoding,\n",
    "            alpha_factor=alpha_factor\n",
    "        ) # Combine rule and data encoding\n",
    "\n",
    "        y = self.decision_block(combined_encodings) # Get final prediction\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6efadb9-2674-4dd0-8828-5d32b0f5189f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc075df-7e4b-46ab-89cf-2284eda03ae7",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dceeaf18-3da0-4f6c-88ab-4f3cd7711711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d98e3123-7d1e-46a2-969a-7456b6a13b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9d82d71-bb80-4ee2-9f14-3b2bc26054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Datasets\n",
    "train = TensorDataset(torch.as_tensor(X_train.values, dtype = torch.float32), torch.as_tensor(y_train.values, dtype = torch.float32))\n",
    "test = TensorDataset(torch.as_tensor(X_test.values, dtype = torch.float32), torch.as_tensor(y_test.values, dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6bcf725-1483-42a7-85ed-fcd5ba628b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "train_dl = DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_dl = DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e758290-7c0f-4125-aa63-b51d03b31b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Sample DataLoader\n",
    "a, b = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1bcf3f2-af3a-4b1f-8fe3-abdca81383dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 19])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f072ad5a-e467-49d6-a310-8086aeac6979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9235391d-a72d-436c-ac83-45ba6ac6c7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "845956b7-3038-44b4-98df-eeff54c9c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model architectures\n",
    "model = Combiner(in_features = 19, out_features = 16, combination_method = \"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80528a84-89fb-4574-b00f-624fb2cd4187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a, .9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46eca5-0ae7-47cb-962e-3848e2643721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2ad57a-164a-4a77-a011-195addb29228",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5c8e1-b36d-48e3-9438-0df553974d89",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df9039e4-243c-48f0-a270-80d6eb05f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch import optim\n",
    "from torch.distributions import Beta, Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b3645f-da66-41f9-9992-9686f034cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "EPOCHS = 1000\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96e9babe-782b-4296-af32-0a48e75b5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Combiner(in_features = 19, out_features = 16, combination_method = \"add\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc1a653-782b-4950-9d07-96075cbf81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.Adam(params=model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1894dd4b-3d9c-47bf-971d-7a2b9cc9b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_criterion(x, x_perturbed, y, y_perturbed):\n",
    "    # MBP = diastolic blood pressure (DBP) + 1/3 [systolic blood pressure (SBP) – DBP].\n",
    "    # BLOOD_PRESSURE = x[:,5] + ((x[:,4] - x[:,5]) / 3) # Calculate mean blood pressure\n",
    "    BLOOD_PRESSURE = x[:,-1] + ((x[:,-2] - x[:,-1]) / 3) # Calculate mean blood pressure\n",
    "    BLOOD_PRESSURE_PERTUBED = x_perturbed[:,-1] + ((x_perturbed[:,-2] - x_perturbed[:,-1]) / 3)\n",
    "    \n",
    "    metric = (y_perturbed - y) / (BLOOD_PRESSURE_PERTUBED - BLOOD_PRESSURE)\n",
    "    \n",
    "    return torch.relu(metric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6dd5ed8-f1ad-4cc3-83ab-6c512c6ebe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test rule criterion\n",
    "rule_criterion(a, a+100, b, b-1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34326058-f499-4487-bbd4-90b81cd763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x, x_perturbed, y, y_perturbed, y_pred, alpha_factor = 0.):\n",
    "    # L = αbLrule + (1 − αb)Ltask\n",
    "    task_loss = criterion(y_pred, y)\n",
    "    # rule_loss = rule_criterion(x, x_perturbed, y, y_perturbed)\n",
    "    rule_loss = rule_criterion(x = x, x_perturbed = x_perturbed, y = y_pred, y_perturbed = y_perturbed)\n",
    "    loss = (alpha_factor * rule_loss) + ((1 - alpha_factor) * task_loss)\n",
    "    \n",
    "    return task_loss, rule_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2bd44d1-0eb0-462e-ae61-9a950420ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Beta distribution instance\n",
    "beta_distribution = Beta(torch.tensor([.1]), torch.tensor([.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6afbd2d8-bb2d-48e6-bc51-f7ae4668e7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0127])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Beta distribution instance\n",
    "beta_distribution.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "080868a0-0bbd-4169-9d21-eea252e1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_data(x, factor = .01):\n",
    "    # Instantiate Uniform distribution instance\n",
    "    uniform_distribution = Uniform(low = 0, high = factor)\n",
    "    gamma = uniform_distribution.sample()\n",
    "\n",
    "    delta_x = gamma * torch.pow(torch.pow(x, 2).sum(), .5)\n",
    "    \n",
    "    return (x + delta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f6a7d-1249-4f5d-8b8d-03490a724198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss:  0.357 | Test loss:  0.329 |  Train accuracy:  0.596 | Test accuracy:  0.601\n",
      "Epoch: 2 | Train loss:  0.374 | Test loss:  0.364 |  Train accuracy:  0.598 | Test accuracy:  0.563\n",
      "Epoch: 3 | Train loss:  0.324 | Test loss:  0.330 |  Train accuracy:  0.598 | Test accuracy:  0.611\n",
      "Epoch: 4 | Train loss:  0.298 | Test loss:  0.307 |  Train accuracy:  0.613 | Test accuracy:  0.613\n",
      "Epoch: 5 | Train loss:  0.319 | Test loss:  0.411 |  Train accuracy:  0.622 | Test accuracy:  0.619\n",
      "Epoch: 6 | Train loss:  0.296 | Test loss:  0.289 |  Train accuracy:  0.622 | Test accuracy:  0.620\n",
      "Epoch: 7 | Train loss:  0.353 | Test loss:  0.311 |  Train accuracy:  0.616 | Test accuracy:  0.627\n",
      "Epoch: 8 | Train loss:  0.297 | Test loss:  0.326 |  Train accuracy:  0.625 | Test accuracy:  0.633\n",
      "Epoch: 9 | Train loss:  0.319 | Test loss:  0.342 |  Train accuracy:  0.623 | Test accuracy:  0.634\n",
      "Epoch: 10 | Train loss:  0.308 | Test loss:  0.306 |  Train accuracy:  0.630 | Test accuracy:  0.633\n",
      "Epoch: 11 | Train loss:  0.294 | Test loss:  0.357 |  Train accuracy:  0.639 | Test accuracy:  0.626\n",
      "Epoch: 12 | Train loss:  0.291 | Test loss:  0.317 |  Train accuracy:  0.633 | Test accuracy:  0.639\n",
      "Epoch: 13 | Train loss:  0.323 | Test loss:  0.299 |  Train accuracy:  0.643 | Test accuracy:  0.639\n",
      "Epoch: 14 | Train loss:  0.298 | Test loss:  0.349 |  Train accuracy:  0.634 | Test accuracy:  0.585\n",
      "Epoch: 15 | Train loss:  0.320 | Test loss:  0.331 |  Train accuracy:  0.633 | Test accuracy:  0.637\n",
      "Epoch: 16 | Train loss:  0.316 | Test loss:  0.321 |  Train accuracy:  0.637 | Test accuracy:  0.629\n",
      "Epoch: 17 | Train loss:  0.302 | Test loss:  0.284 |  Train accuracy:  0.634 | Test accuracy:  0.649\n",
      "Epoch: 18 | Train loss:  0.301 | Test loss:  0.298 |  Train accuracy:  0.640 | Test accuracy:  0.636\n",
      "Epoch: 19 | Train loss:  0.296 | Test loss:  0.294 |  Train accuracy:  0.639 | Test accuracy:  0.631\n",
      "Epoch: 20 | Train loss:  0.305 | Test loss:  0.295 |  Train accuracy:  0.631 | Test accuracy:  0.614\n",
      "Epoch: 21 | Train loss:  0.298 | Test loss:  0.303 |  Train accuracy:  0.641 | Test accuracy:  0.640\n",
      "Epoch: 22 | Train loss:  0.303 | Test loss:  0.302 |  Train accuracy:  0.651 | Test accuracy:  0.611\n",
      "Epoch: 23 | Train loss:  0.355 | Test loss:  0.324 |  Train accuracy:  0.631 | Test accuracy:  0.637\n",
      "Epoch: 24 | Train loss:  0.309 | Test loss:  0.309 |  Train accuracy:  0.634 | Test accuracy:  0.631\n",
      "Epoch: 25 | Train loss:  0.298 | Test loss:  0.327 |  Train accuracy:  0.637 | Test accuracy:  0.643\n",
      "Epoch: 26 | Train loss:  0.291 | Test loss:  0.295 |  Train accuracy:  0.648 | Test accuracy:  0.634\n",
      "Epoch: 27 | Train loss:  0.318 | Test loss:  0.340 |  Train accuracy:  0.639 | Test accuracy:  0.604\n",
      "Epoch: 28 | Train loss:  0.290 | Test loss:  0.330 |  Train accuracy:  0.629 | Test accuracy:  0.636\n",
      "Epoch: 29 | Train loss:  0.306 | Test loss:  0.358 |  Train accuracy:  0.641 | Test accuracy:  0.645\n",
      "Epoch: 30 | Train loss:  0.306 | Test loss:  0.477 |  Train accuracy:  0.629 | Test accuracy:  0.646\n",
      "Epoch: 31 | Train loss:  0.320 | Test loss:  0.367 |  Train accuracy:  0.645 | Test accuracy:  0.632\n",
      "Epoch: 32 | Train loss:  0.305 | Test loss:  0.302 |  Train accuracy:  0.646 | Test accuracy:  0.641\n",
      "Epoch: 33 | Train loss:  0.296 | Test loss:  0.289 |  Train accuracy:  0.644 | Test accuracy:  0.649\n",
      "Epoch: 34 | Train loss:  0.301 | Test loss:  0.334 |  Train accuracy:  0.643 | Test accuracy:  0.548\n",
      "Epoch: 35 | Train loss:  0.301 | Test loss:  0.288 |  Train accuracy:  0.639 | Test accuracy:  0.635\n",
      "Epoch: 36 | Train loss:  0.280 | Test loss:  0.287 |  Train accuracy:  0.630 | Test accuracy:  0.622\n",
      "Epoch: 37 | Train loss:  0.317 | Test loss:  0.359 |  Train accuracy:  0.636 | Test accuracy:  0.642\n",
      "Epoch: 38 | Train loss:  0.319 | Test loss:  0.307 |  Train accuracy:  0.638 | Test accuracy:  0.633\n",
      "Epoch: 39 | Train loss:  0.385 | Test loss:  0.317 |  Train accuracy:  0.628 | Test accuracy:  0.635\n",
      "Epoch: 40 | Train loss:  0.306 | Test loss:  0.315 |  Train accuracy:  0.635 | Test accuracy:  0.629\n",
      "Epoch: 41 | Train loss:  0.308 | Test loss:  0.309 |  Train accuracy:  0.645 | Test accuracy:  0.631\n",
      "Epoch: 42 | Train loss:  0.284 | Test loss:  0.313 |  Train accuracy:  0.643 | Test accuracy:  0.636\n",
      "Epoch: 43 | Train loss:  0.317 | Test loss:  0.336 |  Train accuracy:  0.638 | Test accuracy:  0.635\n",
      "Epoch: 44 | Train loss:  0.285 | Test loss:  0.324 |  Train accuracy:  0.654 | Test accuracy:  0.669\n",
      "Epoch: 45 | Train loss:  0.337 | Test loss:  0.293 |  Train accuracy:  0.637 | Test accuracy:  0.636\n",
      "Epoch: 46 | Train loss:  0.288 | Test loss:  0.312 |  Train accuracy:  0.637 | Test accuracy:  0.657\n",
      "Epoch: 47 | Train loss:  0.292 | Test loss:  0.332 |  Train accuracy:  0.635 | Test accuracy:  0.632\n",
      "Epoch: 48 | Train loss:  0.300 | Test loss:  0.305 |  Train accuracy:  0.644 | Test accuracy:  0.643\n",
      "Epoch: 49 | Train loss:  0.343 | Test loss:  0.407 |  Train accuracy:  0.633 | Test accuracy:  0.627\n",
      "Epoch: 50 | Train loss:  0.285 | Test loss:  0.288 |  Train accuracy:  0.631 | Test accuracy:  0.623\n",
      "Epoch: 51 | Train loss:  0.328 | Test loss:  0.304 |  Train accuracy:  0.628 | Test accuracy:  0.638\n",
      "Epoch: 52 | Train loss:  0.372 | Test loss:  0.304 |  Train accuracy:  0.630 | Test accuracy:  0.639\n",
      "Epoch: 53 | Train loss:  0.297 | Test loss:  0.299 |  Train accuracy:  0.648 | Test accuracy:  0.640\n",
      "Epoch: 54 | Train loss:  0.302 | Test loss:  0.300 |  Train accuracy:  0.646 | Test accuracy:  0.641\n",
      "Epoch: 55 | Train loss:  0.306 | Test loss:  0.292 |  Train accuracy:  0.646 | Test accuracy:  0.640\n",
      "Epoch: 56 | Train loss:  0.281 | Test loss:  0.285 |  Train accuracy:  0.646 | Test accuracy:  0.654\n",
      "Epoch: 57 | Train loss:  0.617 | Test loss:  0.306 |  Train accuracy:  0.634 | Test accuracy:  0.605\n",
      "Epoch: 58 | Train loss:  0.313 | Test loss:  0.329 |  Train accuracy:  0.636 | Test accuracy:  0.634\n",
      "Epoch: 59 | Train loss:  0.293 | Test loss:  0.300 |  Train accuracy:  0.641 | Test accuracy:  0.637\n",
      "Epoch: 60 | Train loss:  0.342 | Test loss:  0.296 |  Train accuracy:  0.637 | Test accuracy:  0.627\n",
      "Epoch: 61 | Train loss:  0.274 | Test loss:  0.317 |  Train accuracy:  0.641 | Test accuracy:  0.633\n",
      "Epoch: 62 | Train loss:  0.599 | Test loss:  0.321 |  Train accuracy:  0.620 | Test accuracy:  0.624\n",
      "Epoch: 63 | Train loss:  0.305 | Test loss:  0.305 |  Train accuracy:  0.623 | Test accuracy:  0.624\n",
      "Epoch: 64 | Train loss:  0.310 | Test loss:  0.284 |  Train accuracy:  0.634 | Test accuracy:  0.632\n",
      "Epoch: 65 | Train loss:  0.318 | Test loss:  0.344 |  Train accuracy:  0.639 | Test accuracy:  0.603\n",
      "Epoch: 66 | Train loss:  0.291 | Test loss:  0.374 |  Train accuracy:  0.645 | Test accuracy:  0.651\n",
      "Epoch: 67 | Train loss:  0.291 | Test loss:  0.293 |  Train accuracy:  0.647 | Test accuracy:  0.639\n",
      "Epoch: 68 | Train loss:  0.347 | Test loss:  0.302 |  Train accuracy:  0.632 | Test accuracy:  0.631\n",
      "Epoch: 69 | Train loss:  0.300 | Test loss:  0.320 |  Train accuracy:  0.642 | Test accuracy:  0.633\n",
      "Epoch: 70 | Train loss:  0.303 | Test loss:  0.290 |  Train accuracy:  0.636 | Test accuracy:  0.636\n",
      "Epoch: 71 | Train loss:  0.344 | Test loss:  0.302 |  Train accuracy:  0.647 | Test accuracy:  0.606\n",
      "Epoch: 72 | Train loss:  0.317 | Test loss:  0.450 |  Train accuracy:  0.625 | Test accuracy:  0.607\n",
      "Epoch: 73 | Train loss:  0.303 | Test loss:  0.305 |  Train accuracy:  0.628 | Test accuracy:  0.633\n",
      "Epoch: 74 | Train loss:  0.283 | Test loss:  0.378 |  Train accuracy:  0.645 | Test accuracy:  0.646\n",
      "Epoch: 75 | Train loss:  0.620 | Test loss:  0.297 |  Train accuracy:  0.594 | Test accuracy:  0.599\n",
      "Epoch: 76 | Train loss:  0.335 | Test loss:  0.434 |  Train accuracy:  0.639 | Test accuracy:  0.637\n",
      "Epoch: 77 | Train loss:  0.311 | Test loss:  0.305 |  Train accuracy:  0.639 | Test accuracy:  0.641\n",
      "Epoch: 78 | Train loss:  0.286 | Test loss:  0.295 |  Train accuracy:  0.652 | Test accuracy:  0.639\n",
      "Epoch: 79 | Train loss:  0.295 | Test loss:  0.362 |  Train accuracy:  0.642 | Test accuracy:  0.641\n",
      "Epoch: 80 | Train loss:  0.296 | Test loss:  0.312 |  Train accuracy:  0.644 | Test accuracy:  0.637\n",
      "Epoch: 81 | Train loss:  0.386 | Test loss:  0.274 |  Train accuracy:  0.643 | Test accuracy:  0.632\n",
      "Epoch: 82 | Train loss:  0.336 | Test loss:  0.304 |  Train accuracy:  0.645 | Test accuracy:  0.643\n",
      "Epoch: 83 | Train loss:  0.304 | Test loss:  0.290 |  Train accuracy:  0.643 | Test accuracy:  0.646\n",
      "Epoch: 84 | Train loss:  0.282 | Test loss:  0.306 |  Train accuracy:  0.645 | Test accuracy:  0.647\n",
      "Epoch: 85 | Train loss:  0.284 | Test loss:  0.307 |  Train accuracy:  0.643 | Test accuracy:  0.628\n",
      "Epoch: 86 | Train loss:  0.281 | Test loss:  0.580 |  Train accuracy:  0.634 | Test accuracy:  0.629\n",
      "Epoch: 87 | Train loss:  0.295 | Test loss:  0.320 |  Train accuracy:  0.650 | Test accuracy:  0.641\n",
      "Epoch: 88 | Train loss:  0.333 | Test loss:  0.363 |  Train accuracy:  0.641 | Test accuracy:  0.650\n",
      "Epoch: 89 | Train loss:  0.300 | Test loss:  0.390 |  Train accuracy:  0.647 | Test accuracy:  0.654\n",
      "Epoch: 90 | Train loss:  0.295 | Test loss:  0.290 |  Train accuracy:  0.633 | Test accuracy:  0.642\n",
      "Epoch: 91 | Train loss:  0.277 | Test loss:  0.282 |  Train accuracy:  0.636 | Test accuracy:  0.641\n",
      "Epoch: 92 | Train loss:  0.290 | Test loss:  0.320 |  Train accuracy:  0.643 | Test accuracy:  0.637\n",
      "Epoch: 93 | Train loss:  0.302 | Test loss:  0.293 |  Train accuracy:  0.648 | Test accuracy:  0.631\n",
      "Epoch: 94 | Train loss:  0.297 | Test loss:  0.315 |  Train accuracy:  0.646 | Test accuracy:  0.634\n",
      "Epoch: 95 | Train loss:  0.303 | Test loss:  0.278 |  Train accuracy:  0.644 | Test accuracy:  0.636\n",
      "Epoch: 96 | Train loss:  0.287 | Test loss:  0.312 |  Train accuracy:  0.649 | Test accuracy:  0.654\n",
      "Epoch: 97 | Train loss:  0.335 | Test loss:  0.300 |  Train accuracy:  0.643 | Test accuracy:  0.636\n",
      "Epoch: 98 | Train loss:  0.296 | Test loss:  0.277 |  Train accuracy:  0.650 | Test accuracy:  0.643\n",
      "Epoch: 99 | Train loss:  0.298 | Test loss:  0.301 |  Train accuracy:  0.643 | Test accuracy:  0.642\n",
      "Epoch: 100 | Train loss:  0.817 | Test loss:  0.285 |  Train accuracy:  0.620 | Test accuracy:  0.621\n",
      "Epoch: 101 | Train loss:  0.329 | Test loss:  0.313 |  Train accuracy:  0.648 | Test accuracy:  0.639\n",
      "Epoch: 102 | Train loss:  0.318 | Test loss:  0.317 |  Train accuracy:  0.639 | Test accuracy:  0.646\n",
      "Epoch: 103 | Train loss:  0.337 | Test loss:  0.322 |  Train accuracy:  0.638 | Test accuracy:  0.623\n",
      "Epoch: 104 | Train loss:  0.288 | Test loss:  0.290 |  Train accuracy:  0.630 | Test accuracy:  0.627\n",
      "Epoch: 105 | Train loss:  0.300 | Test loss:  0.322 |  Train accuracy:  0.637 | Test accuracy:  0.639\n",
      "Epoch: 106 | Train loss:  0.304 | Test loss:  0.287 |  Train accuracy:  0.650 | Test accuracy:  0.634\n",
      "Epoch: 107 | Train loss:  0.283 | Test loss:  0.333 |  Train accuracy:  0.649 | Test accuracy:  0.654\n",
      "Epoch: 108 | Train loss:  0.292 | Test loss:  0.341 |  Train accuracy:  0.671 | Test accuracy:  0.641\n",
      "Epoch: 109 | Train loss:  0.293 | Test loss:  0.294 |  Train accuracy:  0.652 | Test accuracy:  0.637\n",
      "Epoch: 110 | Train loss:  0.291 | Test loss:  0.294 |  Train accuracy:  0.642 | Test accuracy:  0.638\n",
      "Epoch: 111 | Train loss:  0.292 | Test loss:  0.293 |  Train accuracy:  0.652 | Test accuracy:  0.625\n",
      "Epoch: 112 | Train loss:  0.305 | Test loss:  0.313 |  Train accuracy:  0.635 | Test accuracy:  0.608\n",
      "Epoch: 113 | Train loss:  0.291 | Test loss:  0.310 |  Train accuracy:  0.643 | Test accuracy:  0.636\n",
      "Epoch: 114 | Train loss:  0.305 | Test loss:  0.280 |  Train accuracy:  0.650 | Test accuracy:  0.644\n",
      "Epoch: 115 | Train loss:  0.284 | Test loss:  0.295 |  Train accuracy:  0.640 | Test accuracy:  0.636\n",
      "Epoch: 116 | Train loss:  0.287 | Test loss:  0.319 |  Train accuracy:  0.643 | Test accuracy:  0.645\n",
      "Epoch: 117 | Train loss:  0.325 | Test loss:  0.308 |  Train accuracy:  0.649 | Test accuracy:  0.635\n",
      "Epoch: 118 | Train loss:  0.286 | Test loss:  0.307 |  Train accuracy:  0.639 | Test accuracy:  0.640\n",
      "Epoch: 119 | Train loss:  0.276 | Test loss:  0.271 |  Train accuracy:  0.646 | Test accuracy:  0.632\n",
      "Epoch: 120 | Train loss:  0.286 | Test loss:  0.321 |  Train accuracy:  0.650 | Test accuracy:  0.641\n",
      "Epoch: 121 | Train loss:  0.346 | Test loss:  0.346 |  Train accuracy:  0.626 | Test accuracy:  0.558\n",
      "Epoch: 122 | Train loss:  0.878 | Test loss:  0.313 |  Train accuracy:  0.634 | Test accuracy:  0.634\n",
      "Epoch: 123 | Train loss:  0.280 | Test loss:  0.297 |  Train accuracy:  0.634 | Test accuracy:  0.633\n",
      "Epoch: 124 | Train loss:  0.290 | Test loss:  0.307 |  Train accuracy:  0.639 | Test accuracy:  0.630\n",
      "Epoch: 125 | Train loss:  0.292 | Test loss:  0.622 |  Train accuracy:  0.638 | Test accuracy:  0.644\n",
      "Epoch: 126 | Train loss:  0.297 | Test loss:  0.297 |  Train accuracy:  0.638 | Test accuracy:  0.635\n",
      "Epoch: 127 | Train loss:  0.277 | Test loss:  1.099 |  Train accuracy:  0.641 | Test accuracy:  0.644\n",
      "Epoch: 128 | Train loss:  0.330 | Test loss:  0.307 |  Train accuracy:  0.642 | Test accuracy:  0.645\n",
      "Epoch: 129 | Train loss:  0.320 | Test loss:  0.369 |  Train accuracy:  0.644 | Test accuracy:  0.654\n",
      "Epoch: 130 | Train loss:  0.302 | Test loss:  0.317 |  Train accuracy:  0.653 | Test accuracy:  0.604\n",
      "Epoch: 131 | Train loss:  0.285 | Test loss:  0.304 |  Train accuracy:  0.648 | Test accuracy:  0.646\n",
      "Epoch: 132 | Train loss:  0.299 | Test loss:  0.326 |  Train accuracy:  0.647 | Test accuracy:  0.615\n",
      "Epoch: 133 | Train loss:  0.292 | Test loss:  0.284 |  Train accuracy:  0.644 | Test accuracy:  0.643\n",
      "Epoch: 134 | Train loss:  0.300 | Test loss:  0.298 |  Train accuracy:  0.639 | Test accuracy:  0.633\n",
      "Epoch: 135 | Train loss:  0.296 | Test loss:  0.359 |  Train accuracy:  0.637 | Test accuracy:  0.655\n",
      "Epoch: 136 | Train loss:  0.291 | Test loss:  0.301 |  Train accuracy:  0.655 | Test accuracy:  0.630\n",
      "Epoch: 137 | Train loss:  0.452 | Test loss:  0.325 |  Train accuracy:  0.623 | Test accuracy:  0.629\n",
      "Epoch: 138 | Train loss:  0.333 | Test loss:  0.291 |  Train accuracy:  0.633 | Test accuracy:  0.629\n",
      "Epoch: 139 | Train loss:  0.712 | Test loss:  0.313 |  Train accuracy:  0.602 | Test accuracy:  0.624\n",
      "Epoch: 140 | Train loss:  0.306 | Test loss:  0.304 |  Train accuracy:  0.618 | Test accuracy:  0.621\n",
      "Epoch: 141 | Train loss:  0.293 | Test loss:  0.312 |  Train accuracy:  0.637 | Test accuracy:  0.631\n",
      "Epoch: 142 | Train loss:  0.307 | Test loss:  0.310 |  Train accuracy:  0.643 | Test accuracy:  0.649\n",
      "Epoch: 143 | Train loss:  0.434 | Test loss:  0.309 |  Train accuracy:  0.619 | Test accuracy:  0.625\n",
      "Epoch: 144 | Train loss:  0.324 | Test loss:  0.313 |  Train accuracy:  0.632 | Test accuracy:  0.634\n",
      "Epoch: 145 | Train loss:  1.084 | Test loss:  0.634 |  Train accuracy:  0.534 | Test accuracy:  0.585\n",
      "Epoch: 146 | Train loss:  0.333 | Test loss:  0.319 |  Train accuracy:  0.607 | Test accuracy:  0.600\n",
      "Epoch: 147 | Train loss:  0.330 | Test loss:  0.327 |  Train accuracy:  0.616 | Test accuracy:  0.627\n",
      "Epoch: 148 | Train loss:  0.298 | Test loss:  0.347 |  Train accuracy:  0.629 | Test accuracy:  0.629\n",
      "Epoch: 149 | Train loss:  0.302 | Test loss:  0.338 |  Train accuracy:  0.639 | Test accuracy:  0.643\n",
      "Epoch: 150 | Train loss:  0.278 | Test loss:  0.271 |  Train accuracy:  0.640 | Test accuracy:  0.636\n",
      "Epoch: 151 | Train loss:  0.289 | Test loss:  0.309 |  Train accuracy:  0.650 | Test accuracy:  0.647\n",
      "Epoch: 152 | Train loss:  0.304 | Test loss:  0.298 |  Train accuracy:  0.640 | Test accuracy:  0.626\n",
      "Epoch: 153 | Train loss:  0.312 | Test loss:  0.341 |  Train accuracy:  0.639 | Test accuracy:  0.638\n",
      "Epoch: 154 | Train loss:  0.320 | Test loss:  0.275 |  Train accuracy:  0.630 | Test accuracy:  0.622\n",
      "Epoch: 155 | Train loss:  0.301 | Test loss:  0.300 |  Train accuracy:  0.636 | Test accuracy:  0.629\n",
      "Epoch: 156 | Train loss:  0.292 | Test loss:  0.274 |  Train accuracy:  0.639 | Test accuracy:  0.636\n",
      "Epoch: 157 | Train loss:  0.278 | Test loss:  0.299 |  Train accuracy:  0.641 | Test accuracy:  0.648\n",
      "Epoch: 158 | Train loss:  0.269 | Test loss:  0.291 |  Train accuracy:  0.635 | Test accuracy:  0.653\n",
      "Epoch: 159 | Train loss:  0.365 | Test loss:  0.338 |  Train accuracy:  0.644 | Test accuracy:  0.631\n",
      "Epoch: 160 | Train loss:  0.301 | Test loss:  0.330 |  Train accuracy:  0.636 | Test accuracy:  0.631\n",
      "Epoch: 161 | Train loss:  0.289 | Test loss:  0.295 |  Train accuracy:  0.643 | Test accuracy:  0.642\n",
      "Epoch: 162 | Train loss:  0.302 | Test loss:  0.286 |  Train accuracy:  0.649 | Test accuracy:  0.635\n",
      "Epoch: 163 | Train loss:  0.303 | Test loss:  0.320 |  Train accuracy:  0.651 | Test accuracy:  0.645\n",
      "Epoch: 164 | Train loss:  0.298 | Test loss:  0.318 |  Train accuracy:  0.608 | Test accuracy:  0.612\n",
      "Epoch: 165 | Train loss:  0.287 | Test loss:  0.292 |  Train accuracy:  0.642 | Test accuracy:  0.641\n",
      "Epoch: 166 | Train loss:  0.318 | Test loss:  0.309 |  Train accuracy:  0.627 | Test accuracy:  0.640\n",
      "Epoch: 167 | Train loss:  0.293 | Test loss:  0.310 |  Train accuracy:  0.626 | Test accuracy:  0.565\n",
      "Epoch: 168 | Train loss:  0.292 | Test loss:  0.295 |  Train accuracy:  0.601 | Test accuracy:  0.613\n",
      "Epoch: 169 | Train loss:  0.325 | Test loss:  0.419 |  Train accuracy:  0.610 | Test accuracy:  0.452\n",
      "Epoch: 170 | Train loss:  0.309 | Test loss:  0.295 |  Train accuracy:  0.630 | Test accuracy:  0.639\n",
      "Epoch: 171 | Train loss:  0.285 | Test loss:  0.305 |  Train accuracy:  0.640 | Test accuracy:  0.621\n",
      "Epoch: 172 | Train loss:  0.292 | Test loss:  0.321 |  Train accuracy:  0.636 | Test accuracy:  0.632\n",
      "Epoch: 173 | Train loss:  0.274 | Test loss:  0.309 |  Train accuracy:  0.640 | Test accuracy:  0.632\n",
      "Epoch: 174 | Train loss:  0.289 | Test loss:  0.295 |  Train accuracy:  0.641 | Test accuracy:  0.634\n",
      "Epoch: 175 | Train loss:  0.290 | Test loss:  0.374 |  Train accuracy:  0.649 | Test accuracy:  0.647\n",
      "Epoch: 176 | Train loss:  0.282 | Test loss:  0.316 |  Train accuracy:  0.638 | Test accuracy:  0.640\n",
      "Epoch: 177 | Train loss:  0.299 | Test loss:  0.298 |  Train accuracy:  0.635 | Test accuracy:  0.619\n",
      "Epoch: 178 | Train loss:  0.290 | Test loss:  0.293 |  Train accuracy:  0.638 | Test accuracy:  0.644\n",
      "Epoch: 179 | Train loss:  0.451 | Test loss:  0.323 |  Train accuracy:  0.635 | Test accuracy:  0.628\n",
      "Epoch: 180 | Train loss:  0.295 | Test loss:  0.300 |  Train accuracy:  0.638 | Test accuracy:  0.640\n",
      "Epoch: 181 | Train loss:  0.296 | Test loss:  0.282 |  Train accuracy:  0.645 | Test accuracy:  0.623\n",
      "Epoch: 182 | Train loss:  0.289 | Test loss:  0.301 |  Train accuracy:  0.646 | Test accuracy:  0.624\n",
      "Epoch: 183 | Train loss:  0.273 | Test loss:  0.289 |  Train accuracy:  0.628 | Test accuracy:  0.643\n",
      "Epoch: 184 | Train loss:  0.338 | Test loss:  0.316 |  Train accuracy:  0.649 | Test accuracy:  0.641\n",
      "Epoch: 185 | Train loss:  0.327 | Test loss:  0.311 |  Train accuracy:  0.638 | Test accuracy:  0.640\n",
      "Epoch: 186 | Train loss:  0.304 | Test loss:  0.292 |  Train accuracy:  0.647 | Test accuracy:  0.641\n",
      "Epoch: 187 | Train loss:  0.325 | Test loss:  0.292 |  Train accuracy:  0.636 | Test accuracy:  0.643\n",
      "Epoch: 188 | Train loss:  0.306 | Test loss:  0.430 |  Train accuracy:  0.632 | Test accuracy:  0.615\n",
      "Epoch: 189 | Train loss:  0.308 | Test loss:  0.281 |  Train accuracy:  0.640 | Test accuracy:  0.632\n",
      "Epoch: 190 | Train loss:  0.282 | Test loss:  0.330 |  Train accuracy:  0.625 | Test accuracy:  0.636\n",
      "Epoch: 191 | Train loss:  0.275 | Test loss:  0.295 |  Train accuracy:  0.643 | Test accuracy:  0.648\n",
      "Epoch: 192 | Train loss:  0.317 | Test loss:  0.363 |  Train accuracy:  0.625 | Test accuracy:  0.630\n",
      "Epoch: 193 | Train loss:  0.322 | Test loss:  0.305 |  Train accuracy:  0.649 | Test accuracy:  0.624\n",
      "Epoch: 194 | Train loss:  0.335 | Test loss:  0.363 |  Train accuracy:  0.634 | Test accuracy:  0.630\n",
      "Epoch: 195 | Train loss:  0.299 | Test loss:  0.298 |  Train accuracy:  0.647 | Test accuracy:  0.635\n",
      "Epoch: 196 | Train loss:  0.284 | Test loss:  0.273 |  Train accuracy:  0.647 | Test accuracy:  0.644\n",
      "Epoch: 197 | Train loss:  0.277 | Test loss:  0.306 |  Train accuracy:  0.645 | Test accuracy:  0.648\n",
      "Epoch: 198 | Train loss:  0.312 | Test loss:  0.313 |  Train accuracy:  0.650 | Test accuracy:  0.639\n",
      "Epoch: 199 | Train loss:  0.302 | Test loss:  0.303 |  Train accuracy:  0.639 | Test accuracy:  0.640\n",
      "Epoch: 200 | Train loss:  0.343 | Test loss:  0.278 |  Train accuracy:  0.625 | Test accuracy:  0.628\n",
      "Epoch: 201 | Train loss:  0.323 | Test loss:  0.387 |  Train accuracy:  0.632 | Test accuracy:  0.633\n",
      "Epoch: 202 | Train loss:  0.286 | Test loss:  0.296 |  Train accuracy:  0.636 | Test accuracy:  0.651\n",
      "Epoch: 203 | Train loss:  0.296 | Test loss:  0.305 |  Train accuracy:  0.640 | Test accuracy:  0.613\n",
      "Epoch: 204 | Train loss:  0.338 | Test loss:  0.298 |  Train accuracy:  0.622 | Test accuracy:  0.630\n",
      "Epoch: 205 | Train loss:  0.295 | Test loss:  0.298 |  Train accuracy:  0.639 | Test accuracy:  0.639\n",
      "Epoch: 206 | Train loss:  0.297 | Test loss:  0.304 |  Train accuracy:  0.653 | Test accuracy:  0.638\n",
      "Epoch: 207 | Train loss:  0.308 | Test loss:  0.294 |  Train accuracy:  0.654 | Test accuracy:  0.616\n",
      "Epoch: 208 | Train loss:  0.281 | Test loss:  0.347 |  Train accuracy:  0.647 | Test accuracy:  0.659\n",
      "Epoch: 209 | Train loss:  0.313 | Test loss:  0.273 |  Train accuracy:  0.648 | Test accuracy:  0.636\n",
      "Epoch: 210 | Train loss:  0.288 | Test loss:  0.289 |  Train accuracy:  0.638 | Test accuracy:  0.639\n",
      "Epoch: 211 | Train loss:  0.280 | Test loss:  0.352 |  Train accuracy:  0.655 | Test accuracy:  0.647\n",
      "Epoch: 212 | Train loss:  0.284 | Test loss:  0.289 |  Train accuracy:  0.648 | Test accuracy:  0.648\n",
      "Epoch: 213 | Train loss:  0.289 | Test loss:  0.297 |  Train accuracy:  0.652 | Test accuracy:  0.640\n",
      "Epoch: 214 | Train loss:  0.330 | Test loss:  0.296 |  Train accuracy:  0.655 | Test accuracy:  0.637\n",
      "Epoch: 215 | Train loss:  0.277 | Test loss:  0.283 |  Train accuracy:  0.652 | Test accuracy:  0.657\n",
      "Epoch: 216 | Train loss:  0.284 | Test loss:  0.300 |  Train accuracy:  0.650 | Test accuracy:  0.646\n",
      "Epoch: 217 | Train loss:  0.284 | Test loss:  0.278 |  Train accuracy:  0.649 | Test accuracy:  0.644\n",
      "Epoch: 218 | Train loss:  1.088 | Test loss:  0.338 |  Train accuracy:  0.594 | Test accuracy:  0.594\n",
      "Epoch: 219 | Train loss:  0.316 | Test loss:  0.313 |  Train accuracy:  0.618 | Test accuracy:  0.625\n",
      "Epoch: 220 | Train loss:  0.357 | Test loss:  0.334 |  Train accuracy:  0.639 | Test accuracy:  0.583\n",
      "Epoch: 221 | Train loss:  0.310 | Test loss:  0.295 |  Train accuracy:  0.598 | Test accuracy:  0.632\n",
      "Epoch: 222 | Train loss:  1.300 | Test loss:  0.328 |  Train accuracy:  0.634 | Test accuracy:  0.617\n",
      "Epoch: 223 | Train loss:  0.283 | Test loss:  0.294 |  Train accuracy:  0.628 | Test accuracy:  0.630\n",
      "Epoch: 224 | Train loss:  0.302 | Test loss:  0.333 |  Train accuracy:  0.639 | Test accuracy:  0.632\n",
      "Epoch: 225 | Train loss:  0.298 | Test loss:  0.299 |  Train accuracy:  0.645 | Test accuracy:  0.646\n",
      "Epoch: 226 | Train loss:  0.394 | Test loss:  0.307 |  Train accuracy:  0.625 | Test accuracy:  0.630\n",
      "Epoch: 227 | Train loss:  0.343 | Test loss:  0.307 |  Train accuracy:  0.628 | Test accuracy:  0.616\n",
      "Epoch: 228 | Train loss:  0.289 | Test loss:  0.290 |  Train accuracy:  0.630 | Test accuracy:  0.637\n",
      "Epoch: 229 | Train loss:  0.309 | Test loss:  0.301 |  Train accuracy:  0.648 | Test accuracy:  0.640\n",
      "Epoch: 230 | Train loss:  0.296 | Test loss:  0.300 |  Train accuracy:  0.648 | Test accuracy:  0.644\n",
      "Epoch: 231 | Train loss:  0.290 | Test loss:  0.305 |  Train accuracy:  0.647 | Test accuracy:  0.653\n",
      "Epoch: 232 | Train loss:  0.299 | Test loss:  0.366 |  Train accuracy:  0.655 | Test accuracy:  0.647\n",
      "Epoch: 233 | Train loss:  0.331 | Test loss:  0.290 |  Train accuracy:  0.641 | Test accuracy:  0.633\n",
      "Epoch: 234 | Train loss:  0.345 | Test loss:  0.318 |  Train accuracy:  0.612 | Test accuracy:  0.524\n",
      "Epoch: 235 | Train loss:  0.306 | Test loss:  0.276 |  Train accuracy:  0.617 | Test accuracy:  0.630\n",
      "Epoch: 236 | Train loss:  0.301 | Test loss:  0.308 |  Train accuracy:  0.645 | Test accuracy:  0.632\n",
      "Epoch: 237 | Train loss:  0.304 | Test loss:  0.286 |  Train accuracy:  0.643 | Test accuracy:  0.593\n",
      "Epoch: 238 | Train loss:  0.286 | Test loss:  0.415 |  Train accuracy:  0.636 | Test accuracy:  0.636\n",
      "Epoch: 239 | Train loss:  0.276 | Test loss:  0.455 |  Train accuracy:  0.653 | Test accuracy:  0.666\n",
      "Epoch: 240 | Train loss:  0.280 | Test loss:  0.309 |  Train accuracy:  0.652 | Test accuracy:  0.641\n",
      "Epoch: 241 | Train loss:  0.300 | Test loss:  0.290 |  Train accuracy:  0.647 | Test accuracy:  0.670\n",
      "Epoch: 242 | Train loss:  0.285 | Test loss:  0.322 |  Train accuracy:  0.645 | Test accuracy:  0.640\n",
      "Epoch: 243 | Train loss:  0.272 | Test loss:  0.290 |  Train accuracy:  0.654 | Test accuracy:  0.650\n",
      "Epoch: 244 | Train loss:  0.290 | Test loss:  0.297 |  Train accuracy:  0.642 | Test accuracy:  0.635\n",
      "Epoch: 245 | Train loss:  0.290 | Test loss:  0.319 |  Train accuracy:  0.639 | Test accuracy:  0.646\n",
      "Epoch: 246 | Train loss:  0.519 | Test loss:  0.291 |  Train accuracy:  0.637 | Test accuracy:  0.621\n",
      "Epoch: 247 | Train loss:  0.302 | Test loss:  0.316 |  Train accuracy:  0.627 | Test accuracy:  0.604\n",
      "Epoch: 248 | Train loss:  0.286 | Test loss:  0.302 |  Train accuracy:  0.628 | Test accuracy:  0.629\n",
      "Epoch: 249 | Train loss:  0.314 | Test loss:  0.298 |  Train accuracy:  0.632 | Test accuracy:  0.615\n",
      "Epoch: 250 | Train loss:  0.277 | Test loss:  0.478 |  Train accuracy:  0.621 | Test accuracy:  0.624\n",
      "Epoch: 251 | Train loss:  0.420 | Test loss:  0.289 |  Train accuracy:  0.643 | Test accuracy:  0.623\n",
      "Epoch: 252 | Train loss:  0.292 | Test loss:  0.281 |  Train accuracy:  0.627 | Test accuracy:  0.620\n",
      "Epoch: 253 | Train loss:  0.293 | Test loss:  0.309 |  Train accuracy:  0.633 | Test accuracy:  0.639\n",
      "Epoch: 254 | Train loss:  0.294 | Test loss:  0.283 |  Train accuracy:  0.646 | Test accuracy:  0.634\n",
      "Epoch: 255 | Train loss:  0.320 | Test loss:  0.302 |  Train accuracy:  0.626 | Test accuracy:  0.629\n",
      "Epoch: 256 | Train loss:  0.295 | Test loss:  0.277 |  Train accuracy:  0.645 | Test accuracy:  0.634\n",
      "Epoch: 257 | Train loss:  0.286 | Test loss:  0.306 |  Train accuracy:  0.620 | Test accuracy:  0.630\n",
      "Epoch: 258 | Train loss:  0.472 | Test loss:  0.308 |  Train accuracy:  0.630 | Test accuracy:  0.634\n",
      "Epoch: 259 | Train loss:  0.293 | Test loss:  0.309 |  Train accuracy:  0.640 | Test accuracy:  0.650\n",
      "Epoch: 260 | Train loss:  0.299 | Test loss:  0.280 |  Train accuracy:  0.652 | Test accuracy:  0.623\n",
      "Epoch: 261 | Train loss:  0.277 | Test loss:  0.267 |  Train accuracy:  0.654 | Test accuracy:  0.629\n",
      "Epoch: 262 | Train loss:  0.303 | Test loss:  0.325 |  Train accuracy:  0.654 | Test accuracy:  0.646\n",
      "Epoch: 263 | Train loss:  0.278 | Test loss:  0.291 |  Train accuracy:  0.621 | Test accuracy:  0.624\n",
      "Epoch: 264 | Train loss:  0.292 | Test loss:  0.309 |  Train accuracy:  0.658 | Test accuracy:  0.659\n",
      "Epoch: 265 | Train loss:  0.283 | Test loss:  0.311 |  Train accuracy:  0.657 | Test accuracy:  0.660\n",
      "Epoch: 266 | Train loss:  0.287 | Test loss:  0.357 |  Train accuracy:  0.656 | Test accuracy:  0.634\n",
      "Epoch: 267 | Train loss:  0.286 | Test loss:  0.289 |  Train accuracy:  0.642 | Test accuracy:  0.613\n",
      "Epoch: 268 | Train loss:  0.288 | Test loss:  0.283 |  Train accuracy:  0.617 | Test accuracy:  0.612\n",
      "Epoch: 269 | Train loss:  0.362 | Test loss:  0.298 |  Train accuracy:  0.636 | Test accuracy:  0.627\n",
      "Epoch: 270 | Train loss:  0.293 | Test loss:  0.306 |  Train accuracy:  0.639 | Test accuracy:  0.637\n",
      "Epoch: 271 | Train loss:  0.274 | Test loss:  0.306 |  Train accuracy:  0.627 | Test accuracy:  0.629\n",
      "Epoch: 272 | Train loss:  0.281 | Test loss:  0.293 |  Train accuracy:  0.641 | Test accuracy:  0.636\n",
      "Epoch: 273 | Train loss:  0.297 | Test loss:  0.270 |  Train accuracy:  0.655 | Test accuracy:  0.640\n",
      "Epoch: 274 | Train loss:  0.270 | Test loss:  0.293 |  Train accuracy:  0.637 | Test accuracy:  0.632\n",
      "Epoch: 275 | Train loss:  0.295 | Test loss:  0.295 |  Train accuracy:  0.626 | Test accuracy:  0.633\n",
      "Epoch: 276 | Train loss:  0.283 | Test loss:  0.309 |  Train accuracy:  0.651 | Test accuracy:  0.641\n",
      "Epoch: 277 | Train loss:  0.278 | Test loss:  0.292 |  Train accuracy:  0.664 | Test accuracy:  0.645\n",
      "Epoch: 278 | Train loss:  0.314 | Test loss:  0.306 |  Train accuracy:  0.645 | Test accuracy:  0.643\n",
      "Epoch: 279 | Train loss:  0.281 | Test loss:  0.287 |  Train accuracy:  0.649 | Test accuracy:  0.627\n",
      "Epoch: 280 | Train loss:  0.285 | Test loss:  0.323 |  Train accuracy:  0.646 | Test accuracy:  0.643\n",
      "Epoch: 281 | Train loss:  0.285 | Test loss:  0.335 |  Train accuracy:  0.645 | Test accuracy:  0.613\n",
      "Epoch: 282 | Train loss:  0.299 | Test loss:  0.350 |  Train accuracy:  0.642 | Test accuracy:  0.639\n",
      "Epoch: 283 | Train loss:  0.282 | Test loss:  0.287 |  Train accuracy:  0.640 | Test accuracy:  0.641\n",
      "Epoch: 284 | Train loss:  0.282 | Test loss:  0.279 |  Train accuracy:  0.645 | Test accuracy:  0.636\n",
      "Epoch: 285 | Train loss:  0.284 | Test loss:  0.282 |  Train accuracy:  0.637 | Test accuracy:  0.613\n",
      "Epoch: 286 | Train loss:  0.297 | Test loss:  0.303 |  Train accuracy:  0.629 | Test accuracy:  0.650\n",
      "Epoch: 287 | Train loss:  0.274 | Test loss:  0.298 |  Train accuracy:  0.639 | Test accuracy:  0.662\n",
      "Epoch: 288 | Train loss:  0.287 | Test loss:  0.280 |  Train accuracy:  0.656 | Test accuracy:  0.628\n",
      "Epoch: 289 | Train loss:  0.286 | Test loss:  0.319 |  Train accuracy:  0.644 | Test accuracy:  0.614\n",
      "Epoch: 290 | Train loss:  0.288 | Test loss:  0.356 |  Train accuracy:  0.645 | Test accuracy:  0.643\n",
      "Epoch: 291 | Train loss:  0.336 | Test loss:  0.292 |  Train accuracy:  0.639 | Test accuracy:  0.644\n",
      "Epoch: 292 | Train loss:  0.335 | Test loss:  0.313 |  Train accuracy:  0.640 | Test accuracy:  0.632\n",
      "Epoch: 293 | Train loss:  0.287 | Test loss:  0.305 |  Train accuracy:  0.634 | Test accuracy:  0.641\n",
      "Epoch: 294 | Train loss:  0.290 | Test loss:  0.280 |  Train accuracy:  0.641 | Test accuracy:  0.632\n",
      "Epoch: 295 | Train loss:  0.291 | Test loss:  0.292 |  Train accuracy:  0.646 | Test accuracy:  0.648\n",
      "Epoch: 296 | Train loss:  0.305 | Test loss:  0.285 |  Train accuracy:  0.633 | Test accuracy:  0.612\n",
      "Epoch: 297 | Train loss:  1.227 | Test loss:  0.288 |  Train accuracy:  0.623 | Test accuracy:  0.619\n",
      "Epoch: 298 | Train loss:  0.293 | Test loss:  0.270 |  Train accuracy:  0.638 | Test accuracy:  0.625\n",
      "Epoch: 299 | Train loss:  0.286 | Test loss:  0.306 |  Train accuracy:  0.634 | Test accuracy:  0.635\n",
      "Epoch: 300 | Train loss:  0.337 | Test loss:  0.287 |  Train accuracy:  0.635 | Test accuracy:  0.631\n",
      "Epoch: 301 | Train loss:  0.293 | Test loss:  0.284 |  Train accuracy:  0.640 | Test accuracy:  0.634\n",
      "Epoch: 302 | Train loss:  0.295 | Test loss:  0.284 |  Train accuracy:  0.639 | Test accuracy:  0.633\n",
      "Epoch: 303 | Train loss:  0.382 | Test loss:  0.313 |  Train accuracy:  0.626 | Test accuracy:  0.625\n",
      "Epoch: 304 | Train loss:  0.299 | Test loss:  0.287 |  Train accuracy:  0.635 | Test accuracy:  0.630\n",
      "Epoch: 305 | Train loss:  1.353 | Test loss:  0.310 |  Train accuracy:  0.578 | Test accuracy:  0.607\n",
      "Epoch: 306 | Train loss:  0.302 | Test loss:  0.322 |  Train accuracy:  0.610 | Test accuracy:  0.621\n",
      "Epoch: 307 | Train loss:  0.310 | Test loss:  0.307 |  Train accuracy:  0.627 | Test accuracy:  0.626\n",
      "Epoch: 308 | Train loss:  0.320 | Test loss:  0.321 |  Train accuracy:  0.635 | Test accuracy:  0.639\n",
      "Epoch: 309 | Train loss:  0.306 | Test loss:  0.270 |  Train accuracy:  0.639 | Test accuracy:  0.629\n",
      "Epoch: 310 | Train loss:  0.313 | Test loss:  0.303 |  Train accuracy:  0.649 | Test accuracy:  0.616\n",
      "Epoch: 311 | Train loss:  0.340 | Test loss:  0.310 |  Train accuracy:  0.630 | Test accuracy:  0.620\n",
      "Epoch: 312 | Train loss:  0.284 | Test loss:  0.299 |  Train accuracy:  0.629 | Test accuracy:  0.642\n",
      "Epoch: 313 | Train loss:  0.274 | Test loss:  0.297 |  Train accuracy:  0.645 | Test accuracy:  0.662\n",
      "Epoch: 314 | Train loss:  0.333 | Test loss:  0.312 |  Train accuracy:  0.645 | Test accuracy:  0.640\n",
      "Epoch: 315 | Train loss:  0.313 | Test loss:  0.309 |  Train accuracy:  0.665 | Test accuracy:  0.664\n",
      "Epoch: 316 | Train loss:  0.287 | Test loss:  0.298 |  Train accuracy:  0.661 | Test accuracy:  0.637\n",
      "Epoch: 317 | Train loss:  0.314 | Test loss:  0.312 |  Train accuracy:  0.626 | Test accuracy:  0.636\n",
      "Epoch: 318 | Train loss:  0.282 | Test loss:  0.351 |  Train accuracy:  0.626 | Test accuracy:  0.636\n",
      "Epoch: 319 | Train loss:  0.271 | Test loss:  0.279 |  Train accuracy:  0.621 | Test accuracy:  0.626\n",
      "Epoch: 320 | Train loss:  0.296 | Test loss:  0.312 |  Train accuracy:  0.628 | Test accuracy:  0.608\n",
      "Epoch: 321 | Train loss:  0.273 | Test loss:  0.295 |  Train accuracy:  0.633 | Test accuracy:  0.648\n",
      "Epoch: 322 | Train loss:  0.286 | Test loss:  0.281 |  Train accuracy:  0.651 | Test accuracy:  0.645\n",
      "Epoch: 323 | Train loss:  0.315 | Test loss:  0.304 |  Train accuracy:  0.635 | Test accuracy:  0.636\n",
      "Epoch: 324 | Train loss:  0.294 | Test loss:  0.307 |  Train accuracy:  0.634 | Test accuracy:  0.642\n",
      "Epoch: 325 | Train loss:  0.274 | Test loss:  0.304 |  Train accuracy:  0.628 | Test accuracy:  0.608\n",
      "Epoch: 326 | Train loss:  0.295 | Test loss:  0.290 |  Train accuracy:  0.617 | Test accuracy:  0.627\n",
      "Epoch: 327 | Train loss:  0.276 | Test loss:  0.293 |  Train accuracy:  0.633 | Test accuracy:  0.643\n",
      "Epoch: 328 | Train loss:  0.306 | Test loss:  0.305 |  Train accuracy:  0.641 | Test accuracy:  0.651\n",
      "Epoch: 329 | Train loss:  0.296 | Test loss:  0.301 |  Train accuracy:  0.635 | Test accuracy:  0.632\n",
      "Epoch: 330 | Train loss:  0.284 | Test loss:  0.298 |  Train accuracy:  0.650 | Test accuracy:  0.651\n",
      "Epoch: 331 | Train loss:  0.281 | Test loss:  0.302 |  Train accuracy:  0.638 | Test accuracy:  0.639\n",
      "Epoch: 332 | Train loss:  0.283 | Test loss:  0.317 |  Train accuracy:  0.629 | Test accuracy:  0.613\n",
      "Epoch: 333 | Train loss:  0.283 | Test loss:  0.328 |  Train accuracy:  0.620 | Test accuracy:  0.603\n",
      "Epoch: 334 | Train loss:  0.300 | Test loss:  0.302 |  Train accuracy:  0.619 | Test accuracy:  0.633\n",
      "Epoch: 335 | Train loss:  0.296 | Test loss:  0.297 |  Train accuracy:  0.649 | Test accuracy:  0.634\n",
      "Epoch: 336 | Train loss:  0.291 | Test loss:  0.652 |  Train accuracy:  0.642 | Test accuracy:  0.626\n",
      "Epoch: 337 | Train loss:  0.291 | Test loss:  0.302 |  Train accuracy:  0.643 | Test accuracy:  0.640\n",
      "Epoch: 338 | Train loss:  0.272 | Test loss:  0.287 |  Train accuracy:  0.637 | Test accuracy:  0.632\n",
      "Epoch: 339 | Train loss:  0.315 | Test loss:  0.313 |  Train accuracy:  0.649 | Test accuracy:  0.610\n",
      "Epoch: 340 | Train loss:  0.291 | Test loss:  0.291 |  Train accuracy:  0.628 | Test accuracy:  0.637\n",
      "Epoch: 341 | Train loss:  0.299 | Test loss:  0.365 |  Train accuracy:  0.647 | Test accuracy:  0.645\n",
      "Epoch: 342 | Train loss:  0.296 | Test loss:  0.289 |  Train accuracy:  0.647 | Test accuracy:  0.639\n",
      "Epoch: 343 | Train loss:  0.293 | Test loss:  0.334 |  Train accuracy:  0.659 | Test accuracy:  0.574\n",
      "Epoch: 344 | Train loss:  0.331 | Test loss:  0.311 |  Train accuracy:  0.641 | Test accuracy:  0.637\n",
      "Epoch: 345 | Train loss:  0.282 | Test loss:  0.275 |  Train accuracy:  0.626 | Test accuracy:  0.603\n",
      "Epoch: 346 | Train loss:  0.273 | Test loss:  0.280 |  Train accuracy:  0.629 | Test accuracy:  0.620\n",
      "Epoch: 347 | Train loss:  0.297 | Test loss:  0.311 |  Train accuracy:  0.645 | Test accuracy:  0.632\n",
      "Epoch: 348 | Train loss:  0.265 | Test loss:  0.302 |  Train accuracy:  0.659 | Test accuracy:  0.669\n",
      "Epoch: 349 | Train loss:  0.290 | Test loss:  0.295 |  Train accuracy:  0.636 | Test accuracy:  0.633\n",
      "Epoch: 350 | Train loss:  0.304 | Test loss:  0.293 |  Train accuracy:  0.635 | Test accuracy:  0.636\n"
     ]
    }
   ],
   "source": [
    "TRAIN_LOSSES, TEST_LOSSES = [], []\n",
    "TRAIN_ACCS, TEST_ACCS = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "    \n",
    "    train_task_losses, test_task_losses = [], []\n",
    "    train_rule_losses, test_rule_losses = [], []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for X, y in iter(train_dl):\n",
    "        opt.zero_grad()\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        # Get alpha factor\n",
    "        alpha_factor = beta_distribution.sample().to(DEVICE)\n",
    "        \n",
    "        y_pred = model(x = X.to(DEVICE), alpha_factor = alpha_factor).squeeze()\n",
    "\n",
    "        X_perturbed = perturb_data(X, .1)\n",
    "        y_perturbed = model(x = X_perturbed, alpha_factor = alpha_factor)\n",
    "\n",
    "        # Get task and rule losses\n",
    "        \n",
    "        train_task_loss, train_rule_loss, train_loss = get_loss(\n",
    "            x = X, x_perturbed = X_perturbed,\n",
    "            y = y, y_perturbed = y_perturbed,\n",
    "            y_pred = y_pred, alpha_factor = alpha_factor\n",
    "        )\n",
    "        \n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        \n",
    "        train_task_losses.append(train_task_loss.item())\n",
    "        train_rule_losses.append(train_rule_loss.item())\n",
    "\n",
    "        train_acc = accuracy_score(y.cpu().numpy(), (y_pred.detach().cpu().numpy() > .5).astype(int))\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_, y_ in iter(test_dl):\n",
    "            X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "\n",
    "            alpha_factor = beta_distribution.sample().to(DEVICE)\n",
    "            \n",
    "            y_p = model(x = X_, alpha_factor = alpha_factor).squeeze()\n",
    "\n",
    "            X__perturbed = perturb_data(X_, .1)\n",
    "            y__perturbed = model(x = X__perturbed, alpha_factor = alpha_factor)\n",
    "            \n",
    "            test_task_loss, test_rule_loss, test_loss = get_loss(\n",
    "                x = X_, x_perturbed = X__perturbed,\n",
    "                y = y_, y_perturbed = y__perturbed,\n",
    "                y_pred = y_p, alpha_factor = alpha_factor\n",
    "            )\n",
    "            \n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "            test_task_losses.append(test_task_loss.item())\n",
    "            test_rule_losses.append(test_rule_loss.item())\n",
    "\n",
    "            test_acc = accuracy_score(y_.cpu().numpy(), (y_p.detach().cpu().numpy() > .5).astype(int))\n",
    "            test_accs.append(test_acc)\n",
    "        \n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "    avg_train_acc = sum(train_accs) / len(train_accs)\n",
    "    avg_test_acc = sum(test_accs) / len(test_accs)\n",
    "\n",
    "    # Average task losses\n",
    "    avg_train_task_loss = sum(train_task_losses) / len(train_task_losses)\n",
    "    avg_test_task_loss = sum(test_task_losses) / len(test_task_losses)\n",
    "\n",
    "    # Average rule losses\n",
    "    avg_train_rule_loss = sum(train_rule_losses) / len(train_rule_losses)\n",
    "    avg_test_rule_loss = sum(test_rule_losses) / len(test_rule_losses)\n",
    "\n",
    "    # print(\n",
    "    #     f\"Epoch: {epoch+1} | Train loss: {avg_train_loss: .3f} (Task: {avg_train_task_loss: .3f} | Rule: {avg_train_rule_loss: .3f}) |\",\n",
    "    #     f\" Test loss: {avg_test_loss: .3f} (Task: {avg_test_task_loss: .3f} | Rule: {avg_test_rule_loss: .3f}) |\",\n",
    "    #     f\"\\n\\tTrain accuracy: {avg_train_acc: .3f} | Test accuracy: {avg_test_acc: .3f}\"\n",
    "    # )\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1} | Train loss: {avg_train_loss: .3f} | Test loss: {avg_test_loss: .3f} |\",\n",
    "        f\" Train accuracy: {avg_train_acc: .3f} | Test accuracy: {avg_test_acc: .3f}\"\n",
    "    )\n",
    "\n",
    "    TRAIN_LOSSES.append(avg_train_loss)\n",
    "    TEST_LOSSES.append(avg_test_loss)\n",
    "\n",
    "    TRAIN_ACCS.append(avg_train_acc)\n",
    "    TEST_ACCS.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cd80a-0b63-4307-bcd3-17a3dbdab514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
